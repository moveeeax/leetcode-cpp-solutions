# **[Short Encoding of Words](https://leetcode.com/problems/short-encoding-of-words/description/)**  

## **1Ô∏è‚É£ Problem Understanding**  
### **üìå Intuition**  
The main goal of the problem is to encode a list of words by concatenating them with a specific format that avoids redundancy. The format involves appending a word's unique suffix that is not already present in any other words from the list. This can be thought of as achieving minimal concatenation of words while ensuring that each word can be distinctly identified.

### **üöÄ Approach**  
1. **Identify Suffixes**: For every word in the input list, we need to create a mechanism that checks the uniqueness of its suffix within the other words. If the suffix is unique, it should be counted towards the final length of the encoding.
  
2. **Set for Faster Lookups**: We can use a set (or hash set) to store all the words. By iterating through each word and checking if its suffix (constructed by removing prefixes) is in the set, we can determine if it contributes to the encoding.

3. **Iterate & Calculate Length**: For each word, iterate from the end of the word to the start, checking for any matching suffixes in the set. If no match is found, the entire word should be appended to the result.

### **‚è±Ô∏è Complexity Analysis**  
- **Time Complexity**: O(n * m), where n is the number of words and m is the maximum length of a word. This accounts for checking the suffixes of each word in the set.
- **Space Complexity**: O(n), for storing all words in a hash set for quick access.

---  

## **2Ô∏è‚É£ LeetCode Submission**  
```cpp
class Solution {
public:
    int minimumLengthEncoding(vector<string>& words) {
        unordered_set<string> uniqueWords(words.begin(), words.end());
        int totalLength = 0;

        for (const string& word : words) {
            // Check if any suffix of the word exists in the set
            for (int i = 1; i < word.size(); ++i) {
                uniqueWords.erase(word.substr(i));
            }
        }

        // Now only words that contribute to the encoding remain in the set
        for (const string& word : uniqueWords) {
            totalLength += word.size() + 1; // Add 1 for the '#' character
        }

        return totalLength;
    }
};
```  

---  

## **3Ô∏è‚É£ Running Locally**  
### **‚úÖ Steps**  
1. **Create a file**: `short_encoding_of_words.cpp`  
2. **Wrap the `Solution` class** inside `main()`  
3. **Include necessary headers**  
4. **Handle input/output for local execution**  
5. **Compile and run the program**  

---  

## **üìù Full Working Code (Local Execution)**  
```cpp
#include <iostream>
#include <vector>
#include <unordered_set>
#include <string>

using namespace std;

class Solution {
public:
    int minimumLengthEncoding(vector<string>& words) {
        unordered_set<string> uniqueWords(words.begin(), words.end());
        int totalLength = 0;

        for (const string& word : words) {
            for (int i = 1; i < word.size(); ++i) {
                uniqueWords.erase(word.substr(i));
            }
        }

        for (const string& word : uniqueWords) {
            totalLength += word.size() + 1; // Add 1 for the '#' character
        }

        return totalLength;
    }
};

int main() {
    Solution sol;
    vector<string> words = {"time", "me", "bell"};
    cout << sol.minimumLengthEncoding(words) << endl; // Output: 10
    return 0;
}
```  

---  

## **üîß Compilation & Execution**  
#### **1Ô∏è‚É£ Compile**  
```bash
g++ -std=c++17 short_encoding_of_words.cpp -o short_encoding_of_words
```  

#### **2Ô∏è‚É£ Run**  
```bash
./short_encoding_of_words
```  

---  

## **üéØ Example Run**  
### **Input**  
```
["time", "me", "bell"]
```  
### **Output**  
```
10
```  

---  

## **üìå Summary**  
‚úÖ **Encapsulates LeetCode solution inside `main()`**  
‚úÖ **Handles input/output for local testing**  
‚úÖ **Compiles with `g++ -std=c++17`**  
‚úÖ **Provides structured and formatted execution steps**  

üöÄ **Now you can seamlessly test LeetCode C++ solutions locally!** üöÄ// update on 2023-07-10
// update on 2023-07-22
// update on 2023-07-23
